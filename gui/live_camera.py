import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import cv2
import time
import threading
from gtts import gTTS
from playsound import playsound
import tempfile

from vision.detector import ObjectDetector

# =========================
# ğŸ—£ï¸ ØªØ±Ø¬Ù…Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¬Ø³Ø§Ù… Ù„Ù„Ø¹Ø±Ø¨ÙŠ
# =========================
AR_LABELS = {
    "person": "Ø´Ø®Øµ",
    "car": "Ø³ÙŠØ§Ø±Ø©",
    "bus": "Ø­Ø§ÙÙ„Ø©",
    "truck": "Ø´Ø§Ø­Ù†Ø©",
    "motorcycle": "Ø¯Ø±Ø§Ø¬Ø© Ù†Ø§Ø±ÙŠØ©",
    "bicycle": "Ø¯Ø±Ø§Ø¬Ø©",
    "chair": "ÙƒØ±Ø³ÙŠ",
    "bench": "Ù…Ù‚Ø¹Ø¯",
    "dog": "ÙƒÙ„Ø¨",
    "cat": "Ù‚Ø·",
    "cell phone": "Ù‡Ø§ØªÙ",
    "laptop": "Ø­Ø§Ø³ÙˆØ¨ Ù…Ø­Ù…ÙˆÙ„",
    "tv": "ØªÙ„ÙØ§Ø²",
    "door": "Ø¨Ø§Ø¨",
    "cup": "ÙƒÙˆØ¨",
}

def translate_label(label):
    return AR_LABELS.get(label, label)

# =========================
# ğŸ”Š ØµÙˆØª ØºÙŠØ± Ù…Ø¹Ù„Ù‚ (Thread)
# =========================
def speak_async(text):
    def run():
        try:
            tts = gTTS(text=text, lang="ar")
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
                filename = fp.name
            tts.save(filename)
            playsound(filename)
            os.remove(filename)
        except Exception as e:
            print("Ø®Ø·Ø£ ØµÙˆØª:", e)

    threading.Thread(target=run, daemon=True).start()

# =========================
# ğŸ§  Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ù„Ù…Ø³Ø§ÙØ©
# =========================
def get_direction(bbox, w):
    x1, _, x2, _ = bbox
    cx = (x1 + x2) / 2
    if cx < w / 3:
        return "Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±"
    elif cx > 2 * w / 3:
        return "Ø¹Ù„Ù‰ Ø§Ù„ÙŠÙ…ÙŠÙ†"
    else:
        return "Ø£Ù…Ø§Ù…Ùƒ"

def get_distance(bbox, area):
    x1, y1, x2, y2 = bbox
    a = (x2 - x1) * (y2 - y1)
    r = a / area
    if r > 0.2:
        return "Ù‚Ø±ÙŠØ¨"
    elif r > 0.08:
        return "Ù…ØªÙˆØ³Ø·"
    else:
        return "Ø¨Ø¹ÙŠØ¯"

# =========================
# ğŸ¥ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
# =========================
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("âŒ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù„Ø§ ØªØ¹Ù…Ù„")
    exit()

detector = ObjectDetector(conf=0.2)

print("âœ… Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ¹Ù…Ù„ â€” Ø§Ø¶ØºØ· Q Ù„Ù„Ø®Ø±ÙˆØ¬")

LAST_SPEAK = 0
INTERVAL = 4  # Ø«ÙˆØ§Ù†ÙŠ

while True:
    ret, frame = cap.read()
    if not ret:
        break

    h, w = frame.shape[:2]
    area = h * w

    frame, detections = detector.detect(frame)

    if detections:
        # Ø§Ø®ØªÙŠØ§Ø± Ø£Ù‚Ø±Ø¨ Ø¬Ø³Ù…
        d = max(
            detections,
            key=lambda x: (x["bbox"][2]-x["bbox"][0]) * (x["bbox"][3]-x["bbox"][1])
        )

        bbox = d["bbox"]
        label_en = d["label"]
        label_ar = translate_label(label_en)

        direction = get_direction(bbox, w)
        distance = get_distance(bbox, area)

        x1, y1, x2, y2 = bbox
        cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)
        cv2.putText(
            frame,
            f"{label_ar} | {direction} | {distance}",
            (x1, y1-10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0,255,0),
            2
        )

        now = time.time()
        if now - LAST_SPEAK >= INTERVAL:
            speak_async(f"ÙŠÙˆØ¬Ø¯ {label_ar} {direction} ÙˆÙ‡Ùˆ {distance}")
            LAST_SPEAK = now

    cv2.imshow("AI Visual Assistant - Live", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()
